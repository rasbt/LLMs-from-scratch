{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb3d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06be3418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5500, 0.8700, 0.6600])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_query = inputs[1]\n",
    "input_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1e4494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4300, 0.1500, 0.8900])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = inputs[0]\n",
    "input_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153ad590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9544)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(input_query, input_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42743f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9544)\n"
     ]
    }
   ],
   "source": [
    "res = 0.\n",
    "i = 0\n",
    "\n",
    "res = torch.dot(inputs[i], input_query)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f84e783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, input_query)\n",
    "\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b64ddf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize scores \n",
    "\n",
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "attn_weights_2_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d7bfece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax self-implementation\n",
    "\n",
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "softmax_naive(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173e3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch implementation - use this when you can\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "816bf1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1] # 2nd input token is the query in this example\n",
    "\n",
    "context_vec_2 = torch.zeros(query.shape) # empty context vector of same shape as input vectors (for second context vector)\n",
    "\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i] * x_i # weighted sum done here\n",
    "\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f87df",
   "metadata": {},
   "source": [
    "### Simple self-attention mechanism without trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1398c3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "# Manual implementaton with for loops\n",
    "\n",
    "attn_scores = torch.empty(6,6)\n",
    "\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cc0927a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication to calculate the above MUCH quicker with special notation\n",
    "\n",
    "attn_scores = inputs @ inputs.T\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3e22c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=1) # weights along the rows (dim 1) add to 1\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "187f9de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use matrix multiplication to find all 6 context vectors\n",
    "\n",
    "all_context_vecs = attn_weights @ inputs\n",
    "all_context_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f61cc",
   "metadata": {},
   "source": [
    "#### In one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd5b93d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "all_context_vecs = attn_weights @ inputs\n",
    "all_context_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e3239c",
   "metadata": {},
   "source": [
    "## 3.4 Implementing self-attention with trainable weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcba95",
   "metadata": {},
   "source": [
    "### 3.4.1 Computing the attention weights step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beccda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2 # the user can pick these! Can make it the size you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0149c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out)) # torch.nn.Parameter is a wrapper around a tensor to make it trainable\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df08ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4306, 1.4551], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "\n",
    "query_2\n",
    "\n",
    "# turning the 3-d input tensor into a 2-d query tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "757daab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query is reused everywhere (when comparing to every other token). However, keys (and values) are unique when used in relation to other tokens. Basically we need to find the key vector of the inputs for every other token in the context (which is full matrix multiplication instead of a vector dotted with a matrix)\n",
    "\n",
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "\n",
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fabd1cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3669, 0.7646],\n",
       "        [0.4433, 1.1419],\n",
       "        [0.4361, 1.1156],\n",
       "        [0.2408, 0.6706],\n",
       "        [0.1827, 0.3292],\n",
       "        [0.3275, 0.9642]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba12fe66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8524, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_2 = keys[1] \n",
    "attn_score_22 = torch.dot(query_2, keys_2)\n",
    "attn_score_22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c5814",
   "metadata": {},
   "source": [
    "#### Calculating attn *scores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5126a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
       "       grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can compute the attn score for the entire context (from the reference point of the second token) by matrix multiplying the query embedding of the 2nd token with the tensor of the key values for all the tokens in the context.\n",
    "\n",
    "attn_scores_2 = query_2 @ keys.T\n",
    "attn_scores_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac51a8",
   "metadata": {},
   "source": [
    "#### Calculating attn *weights* with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "408f1f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = keys.shape[1]\n",
    "\n",
    "# normalizing the attention scores with the dimensions of the key matrix\n",
    "\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k ** 0.5, dim=-1) # row-wise softmax -> we are normalizing the key vectors entirely (dim = 0 treats the first entry of each key as a column vector then normalizes)\n",
    "attn_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "833da6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalized weights should sum up to 1\n",
    "\n",
    "sum(attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10f3615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3061, 0.8210], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context vector is the attn weighted sum of all the value vectors (another matrix multiplication)\n",
    "\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "\n",
    "context_vec_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ed260",
   "metadata": {},
   "source": [
    "In summary, the queries and keys together are used to find the **attention scores** which are then normalized and softmaxxed into **attention weights**. The values are applied to all the attention weights to compute the **context vectors**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d618bec",
   "metadata": {},
   "source": [
    "### 3.4.2 Implementing a compact self-attention class\n",
    "\n",
    "We are trying now to get the context vector for all the other input tokens (previously we did it just for the second token) by reusing the code from 3.4.1 to make a reusable class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77a816d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2996, 0.8053],\n",
       "        [0.3061, 0.8210],\n",
       "        [0.3058, 0.8203],\n",
       "        [0.2948, 0.7939],\n",
       "        [0.2927, 0.7891],\n",
       "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_V1(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.rand(d_in, d_out)) # torch.nn.Parameter is a wrapper around a tensor to make it trainable\n",
    "        self.W_key = torch.nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = torch.nn.Parameter(torch.rand(d_in, d_out))   \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        queries = inputs @ W_query\n",
    "        keys = inputs @ W_key\n",
    "        values = inputs @ W_value\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "\n",
    "        return context_vec\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_V1(d_in, d_out)\n",
    "sa_v1(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd512b4",
   "metadata": {},
   "source": [
    "Note in the code above that sa_v1[inputs][1] = [0.3061, 0.8210], which means the class works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22b02aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2911,  0.5878, -0.0934], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.nn.Linear(2,3)\n",
    "m.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6aac57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0739,  0.0713],\n",
       "        [-0.0748,  0.0703],\n",
       "        [-0.0749,  0.0702],\n",
       "        [-0.0760,  0.0685],\n",
       "        [-0.0763,  0.0679],\n",
       "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Self attention with linear layers (better implementation)\n",
    "\n",
    "class SelfAttention_V2(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, qkv_bias=False): # the bias term in the nn.Linear, which we don't need (not using a bias in this nn I guess?)\n",
    "        super().__init__()\n",
    "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias) # torch.nn.Linear is an alternative to nn.Parameter (not sure what the benefit is aside from no explicit torch.rand call needed, slightly better weight initialization under the hood according to Sebastian)\n",
    "        self.W_key = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)  \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        queries = self.W_query(inputs) # similar behavior -> we are still doing matrix multiplication\n",
    "        keys = self.W_key(inputs)\n",
    "        values = self.W_value(inputs)\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "\n",
    "        return context_vec\n",
    "    \n",
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_V2(d_in, d_out)\n",
    "sa_v2(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ea14dc",
   "metadata": {},
   "source": [
    "## 3.5 Hiding future words with causal attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ca20f",
   "metadata": {},
   "source": [
    "For a predictive model, it doesn't make sense for the model to know future words in the context (relative to the current token being looked at)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6566e372",
   "metadata": {},
   "source": [
    "### 3.5.1 Applying a causal attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217883f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
