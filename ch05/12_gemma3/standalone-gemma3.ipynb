{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e1b280ab-b61f-4d1a-bf7e-44e5f9ed3a5c",
      "metadata": {
        "id": "e1b280ab-b61f-4d1a-bf7e-44e5f9ed3a5c"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
        "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efde77f2-6af3-4781-8597-89ecd3f41a52",
      "metadata": {
        "id": "efde77f2-6af3-4781-8597-89ecd3f41a52"
      },
      "source": [
        "# Gemma 3 270M From Scratch (A Standalone Notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55cdef4d-de59-4a65-89f9-fa2a8ef3471d",
      "metadata": {
        "id": "55cdef4d-de59-4a65-89f9-fa2a8ef3471d"
      },
      "source": [
        "- This notebook is purposefully minimal and focuses on the code to re-implement Gemma 3 270M in pure PyTorch without relying on other external LLM libraries\n",
        "- For more information, see the official [Gemma 3 270M model card](https://huggingface.co/google/gemma-3-270m)\n",
        "\n",
        "- Below is a side-by-side comparison with Qwen3 0.6B as a reference model; if you are interested in the Qwen3 0.6B standalone notebook, you can find it [here](../11_qwen3)\n",
        "<br>\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/gemma3/gemma3-vs-qwen3.webp?1\">\n",
        "  \n",
        "  \n",
        "- About the code:\n",
        "  - all code is my own code, mapping the Gemma 3 architecture onto the model code implemented in my [Build A Large Language Model (From Scratch)](http://mng.bz/orYv) book; the code is released under a permissive open-source Apache 2.0 license (see [LICENSE.txt](https://github.com/rasbt/LLMs-from-scratch/blob/main/LICENSE.txt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7c201adb-747e-437b-9a62-442802941e01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7c201adb-747e-437b-9a62-442802941e01",
        "outputId": "b2247f5a-44d7-4ba4-c053-6e0762d6b9fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: blobfile>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.24.7 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (0.34.4)\n",
            "Collecting ipywidgets>=8.1.2 (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3))\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 5)) (0.2.1)\n",
            "Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.11/dist-packages (from blobfile>=3.0.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 1)) (3.23.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile>=3.0.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile>=3.0.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 1)) (5.4.0)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile>=3.0.0->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24.7->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24.7->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24.7->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24.7->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24.7->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24.7->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.24.7->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (1.1.7)\n",
            "Collecting comm>=0.1.3 (from ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3))\n",
            "  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3))\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (3.0.15)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.24.7->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.24.7->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.24.7->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 2)) (2025.8.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.1.2->-r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt (line 3)) (0.2.13)\n",
            "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: widgetsnbextension, jedi, comm, ipywidgets\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.3 ipywidgets-8.1.7 jedi-0.19.2 widgetsnbextension-4.0.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipywidgets"
                ]
              },
              "id": "b7a9aac258d5440cbcc05f0d6e8d98f8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dd1b65a8-4301-444a-bd7c-a6f2bd1df9df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd1b65a8-4301-444a-bd7c-a6f2bd1df9df",
        "outputId": "d341dca2-3a62-4487-e2a8-e855d6a1bb5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "huggingface_hub version: 0.34.4\n",
            "tokenizers version: 0.21.4\n",
            "torch version: 2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "# 定义需要检查版本的包列表\n",
        "pkgs = [\n",
        "    \"huggingface_hub\",  # 用于下载预训练权重\n",
        "    \"tokenizers\",       # 用于实现分词器\n",
        "    \"torch\",            # 用于实现模型\n",
        "]\n",
        "# 遍历包列表并打印每个包的版本\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e96fbb-8e16-4f6d-835f-c6159321280b",
      "metadata": {
        "id": "07e96fbb-8e16-4f6d-835f-c6159321280b"
      },
      "source": [
        "- This notebook supports both the base model and the instructmodel; which model to use can be controlled via the following flag:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "70a90338-624a-4706-aa55-6b4358070194",
      "metadata": {
        "id": "70a90338-624a-4706-aa55-6b4358070194"
      },
      "outputs": [],
      "source": [
        "# 定义一个布尔标志，用于控制是否使用指令模型\n",
        "USE_INSTRUCT_MODEL = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "653410a6-dd2b-4eb2-a722-23d9782e726d",
      "metadata": {
        "id": "653410a6-dd2b-4eb2-a722-23d9782e726d"
      },
      "source": [
        "&nbsp;\n",
        "# 1. Architecture code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "82076c21-9331-4dcd-b017-42b046cf1a60",
      "metadata": {
        "id": "82076c21-9331-4dcd-b017-42b046cf1a60"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 定义前馈网络类\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # 定义第一个线性层，输入维度 emb_dim，输出维度 hidden_dim\n",
        "        self.fc1 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
        "        # 定义第二个线性层，输入维度 emb_dim，输出维度 hidden_dim\n",
        "        self.fc2 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
        "        # 定义第三个线性层，输入维度 hidden_dim，输出维度 emb_dim\n",
        "        self.fc3 = nn.Linear(cfg[\"hidden_dim\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
        "\n",
        "    # 定义前向传播\n",
        "    def forward(self, x):\n",
        "        # 应用第一个线性层\n",
        "        x_fc1 = self.fc1(x)\n",
        "        # 应用第二个线性层\n",
        "        x_fc2 = self.fc2(x)\n",
        "        # 应用 GELU 激活函数并与 x_fc2 相乘\n",
        "        x = nn.functional.gelu(x_fc1, approximate=\"tanh\") * x_fc2\n",
        "        # 应用第三个线性层\n",
        "        return self.fc3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "56715760-37e1-433e-89da-04864c139a9e",
      "metadata": {
        "id": "56715760-37e1-433e-89da-04864c139a9e"
      },
      "outputs": [],
      "source": [
        "# 定义 RMSNorm 类\n",
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, emb_dim, eps=1e-6, bias=False):\n",
        "        super().__init__()\n",
        "        self.eps = eps # 定义 epsilon，用于防止除零\n",
        "        # Gemma3 存储零中心权重并在前向传播中使用 (1 + weight)\n",
        "        self.scale = nn.Parameter(torch.zeros(emb_dim)) # 定义可学习的缩放参数\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim)) if bias else None # 定义可选的可学习的偏移参数\n",
        "\n",
        "    # 定义前向传播\n",
        "    def forward(self, x):\n",
        "        # 匹配 HF Gemma3：在 float32 中计算范数，然后按 (1 + w) 缩放\n",
        "        input_dtype = x.dtype # 保存输入数据的原始数据类型\n",
        "        x_f = x.float() # 将输入数据转换为 float32\n",
        "        var = x_f.pow(2).mean(dim=-1, keepdim=True) # 计算输入数据的方差\n",
        "        x_norm = x_f * torch.rsqrt(var + self.eps) # 应用 RMS 归一化\n",
        "        out = x_norm * (1.0 + self.scale.float()) # 应用缩放\n",
        "\n",
        "        # 如果存在偏移参数，则应用偏移\n",
        "        if self.shift is not None:\n",
        "            out = out + self.shift.float()\n",
        "\n",
        "        return out.to(input_dtype) # 将输出数据转换回原始数据类型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4b9a346f-5826-4083-9162-abd56afc03f0",
      "metadata": {
        "id": "4b9a346f-5826-4083-9162-abd56afc03f0"
      },
      "outputs": [],
      "source": [
        "# 计算 RoPE (Rotary Positional Embedding) 参数\n",
        "def compute_rope_params(head_dim, theta_base=10_000, context_length=4096, dtype=torch.float32):\n",
        "    assert head_dim % 2 == 0, \"Embedding dimension must be even\" # 确保 embedding 维度是偶数\n",
        "\n",
        "    # 计算逆频率\n",
        "    # 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n",
        "    inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n",
        "\n",
        "    # 生成位置索引\n",
        "    positions = torch.arange(context_length, dtype=dtype)\n",
        "\n",
        "    # 计算角度\n",
        "    # positions[:, None] 的形状是 (context_length, 1)\n",
        "    # inv_freq[None, :] 的形状是 (1, head_dim // 2)\n",
        "    # 相乘得到形状为 (context_length, head_dim // 2) 的角度\n",
        "    angles = positions[:, None] * inv_freq[None, :]\n",
        "\n",
        "    # 扩展角度以匹配 head_dim\n",
        "    # 将角度自身连接起来，得到形状为 (context_length, head_dim)\n",
        "    angles = torch.cat([angles, angles], dim=1)\n",
        "\n",
        "    # 预计算 sine 和 cosine\n",
        "    cos = torch.cos(angles)\n",
        "    sin = torch.sin(angles)\n",
        "\n",
        "    return cos, sin # 返回 cosine 和 sine\n",
        "\n",
        "# 应用 RoPE\n",
        "def apply_rope(x, cos, sin):\n",
        "    # x: (batch_size, num_heads, seq_len, head_dim)\n",
        "    batch_size, num_heads, seq_len, head_dim = x.shape\n",
        "    assert head_dim % 2 == 0, \"Head dimension must be even\" # 确保 head 维度是偶数\n",
        "\n",
        "    # 将 x 分割成前半部分和后半部分\n",
        "    x1 = x[..., : head_dim // 2]  # 前半部分\n",
        "    x2 = x[..., head_dim // 2 :]  # 后半部分\n",
        "\n",
        "    # 调整 sin 和 cos 的形状以进行广播\n",
        "    # unsqueeze(0) 两次，添加批次维度和头维度，形状变为 (1, 1, seq_len, head_dim)\n",
        "    cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)\n",
        "    sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    # 应用旋转变换\n",
        "    # 将 x2 的符号取反并与 x1 连接，得到旋转后的向量\n",
        "    rotated = torch.cat((-x2, x1), dim=-1)\n",
        "    # 应用 RoPE 公式: x * cos + rotated * sin\n",
        "    x_rotated = (x * cos) + (rotated * sin)\n",
        "\n",
        "    # 应用 cos 和 sin 旋转后可以使用较低精度\n",
        "    return x_rotated.to(dtype=x.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e8169ab5-f976-4222-a2e1-eb1cabf267cb",
      "metadata": {
        "id": "e8169ab5-f976-4222-a2e1-eb1cabf267cb"
      },
      "outputs": [],
      "source": [
        "# 定义分组查询注意力机制 (Grouped Query Attention)\n",
        "class GroupedQueryAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self, d_in, num_heads, num_kv_groups, head_dim=None, qk_norm=False,\n",
        "        query_pre_attn_scalar=None, dtype=None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # 确保 num_heads 能被 num_kv_groups 整除\n",
        "        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n",
        "\n",
        "        self.num_heads = num_heads # 查询头的数量\n",
        "        self.num_kv_groups = num_kv_groups # KV 组的数量\n",
        "        self.group_size = num_heads // num_kv_groups # 每个 KV 组对应的查询头数量\n",
        "\n",
        "        # 如果 head_dim 没有设置，则根据 d_in 和 num_heads 计算\n",
        "        if head_dim is None:\n",
        "            assert d_in % num_heads == 0, \"`d_in` must be divisible by `num_heads` if `head_dim` is not set\"\n",
        "            head_dim = d_in // num_heads\n",
        "\n",
        "        self.head_dim = head_dim # 每个头的维度\n",
        "        self.d_out = num_heads * head_dim # 输出维度\n",
        "\n",
        "        # 定义查询、键、值的线性投影层\n",
        "        self.W_query = nn.Linear(d_in, self.d_out, bias=False, dtype=dtype) # 查询投影\n",
        "        self.W_key = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype) # 键投影\n",
        "        self.W_value = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype) # 值投影\n",
        "\n",
        "        # 定义输出投影层\n",
        "        self.out_proj = nn.Linear(self.d_out, d_in, bias=False, dtype=dtype)\n",
        "\n",
        "        # 如果需要进行 QK 归一化，则定义 Q 归一化和 K 归一化层\n",
        "        if qk_norm:\n",
        "            self.q_norm = RMSNorm(head_dim, eps=1e-6)\n",
        "            self.k_norm = RMSNorm(head_dim, eps=1e-6)\n",
        "        else:\n",
        "            self.q_norm = self.k_norm = None\n",
        "\n",
        "        # 计算缩放因子\n",
        "        if query_pre_attn_scalar is not None:\n",
        "            self.scaling = (query_pre_attn_scalar) ** -0.5\n",
        "        else:\n",
        "            self.scaling = (head_dim) ** -0.5\n",
        "\n",
        "\n",
        "    # 定义前向传播\n",
        "    def forward(self, x, mask, cos, sin):\n",
        "        b, num_tokens, _ = x.shape # 获取批次大小和序列长度\n",
        "\n",
        "        # 应用投影层\n",
        "        queries = self.W_query(x)  # (b, num_tokens, num_heads * head_dim)\n",
        "        keys = self.W_key(x)       # (b, num_tokens, num_kv_groups * head_dim)\n",
        "        values = self.W_value(x)   # (b, num_tokens, num_kv_groups * head_dim)\n",
        "\n",
        "        # 重塑形状以进行多头注意力计算\n",
        "        # 将 num_heads * head_dim 拆分成 num_heads 和 head_dim\n",
        "        # 转置维度 1 和 2，使头的维度在前\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        # 将 num_kv_groups * head_dim 拆分成 num_kv_groups 和 head_dim\n",
        "        # 转置维度 1 和 2，使 KV 组的维度在前\n",
        "        keys = keys.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
        "        values = values.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # 可选的归一化\n",
        "        if self.q_norm:\n",
        "            queries = self.q_norm(queries)\n",
        "        if self.k_norm:\n",
        "            keys = self.k_norm(keys)\n",
        "\n",
        "        # 应用 RoPE\n",
        "        queries = apply_rope(queries, cos, sin)\n",
        "        keys = apply_rope(keys, cos, sin)\n",
        "\n",
        "        # 扩展 K 和 V 以匹配查询头的数量\n",
        "        # 使用 repeat_interleave 将每个 KV 组重复 group_size 次\n",
        "        keys = keys.repeat_interleave(self.group_size, dim=1)\n",
        "        values = values.repeat_interleave(self.group_size, dim=1)\n",
        "\n",
        "        # 缩放查询\n",
        "        queries = queries * self.scaling\n",
        "\n",
        "        # 计算注意力分数\n",
        "        # 查询与键的转置相乘\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        # 应用掩码，将需要屏蔽的位置设置为负无穷\n",
        "        attn_scores = attn_scores.masked_fill(mask, -torch.inf)\n",
        "        # 应用 softmax 计算注意力权重\n",
        "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # 计算上下文向量\n",
        "        # 注意力权重与值相乘\n",
        "        context = (attn_weights @ values).transpose(1, 2).reshape(b, num_tokens, self.d_out)\n",
        "        # 应用输出投影层\n",
        "        return self.out_proj(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "457cb2f8-50c1-4045-8a74-f181bfb5fea9",
      "metadata": {
        "id": "457cb2f8-50c1-4045-8a74-f181bfb5fea9"
      },
      "outputs": [],
      "source": [
        "# 定义 Transformer 块\n",
        "class TransformerBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg: dict, attn_type: str):\n",
        "        super().__init__()\n",
        "        self.attn_type = attn_type # 定义注意力类型 (滑动窗口注意力或全局注意力)\n",
        "\n",
        "        # 定义分组查询注意力层\n",
        "        self.att = GroupedQueryAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            num_kv_groups=cfg[\"n_kv_groups\"],\n",
        "            head_dim=cfg[\"head_dim\"],\n",
        "            qk_norm=cfg[\"qk_norm\"],\n",
        "            query_pre_attn_scalar=cfg[\"query_pre_attn_scalar\"],\n",
        "            dtype=cfg[\"dtype\"],\n",
        "        )\n",
        "        # 定义前馈网络层\n",
        "        self.ff = FeedForward(cfg)\n",
        "        # 定义各种 LayerNorm 层\n",
        "        self.input_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6) # 输入 LayerNorm\n",
        "        self.post_attention_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6) # 注意力后 LayerNorm\n",
        "        self.pre_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6) # 前馈网络前 LayerNorm\n",
        "        self.post_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6) # 前馈网络后 LayerNorm\n",
        "\n",
        "    # 定义前向传播\n",
        "    def forward(\n",
        "        self,\n",
        "        x,\n",
        "        mask_global, # 全局注意力掩码\n",
        "        mask_local, # 滑动窗口注意力掩码\n",
        "        cos_global, # 全局 RoPE cos\n",
        "        sin_global, # 全局 RoPE sin\n",
        "        cos_local, # 滑动窗口 RoPE cos\n",
        "        sin_local, # 滑动窗口 RoPE sin\n",
        "    ):\n",
        "        # 注意力块的 shortcut 连接\n",
        "        shortcut = x\n",
        "        # 对输入应用 LayerNorm\n",
        "        x = self.input_layernorm(x)\n",
        "\n",
        "        # 根据注意力类型选择对应的掩码和 RoPE 参数\n",
        "        if self.attn_type == \"sliding_attention\":\n",
        "            attn_mask = mask_local\n",
        "            cos = cos_local\n",
        "            sin = sin_local\n",
        "        else:\n",
        "            attn_mask = mask_global\n",
        "            cos = cos_global\n",
        "            sin = sin_global\n",
        "\n",
        "        # 应用注意力机制\n",
        "        x_attn = self.att(x, attn_mask, cos, sin)\n",
        "        # 对注意力输出应用 LayerNorm\n",
        "        x_attn = self.post_attention_layernorm(x_attn)\n",
        "        # 将注意力输出加到 shortcut 连接上\n",
        "        x = shortcut + x_attn\n",
        "\n",
        "        # 前馈块的 shortcut 连接\n",
        "        shortcut = x\n",
        "        # 对输入应用前馈网络前的 LayerNorm\n",
        "        x_ffn = self.pre_feedforward_layernorm(x)\n",
        "        # 应用前馈网络\n",
        "        x_ffn = self.ff(x_ffn)\n",
        "        # 对前馈网络输出应用后 LayerNorm\n",
        "        x_ffn = self.post_feedforward_layernorm(x_ffn)\n",
        "        # 将前馈网络输出加到 shortcut 连接上\n",
        "        x = shortcut + x_ffn\n",
        "        return x # 返回 Transformer 块的输出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e88de3e3-9f07-42cc-816b-28dbd46e96c4",
      "metadata": {
        "id": "e88de3e3-9f07-42cc-816b-28dbd46e96c4"
      },
      "outputs": [],
      "source": [
        "# 定义 Gemma3 模型\n",
        "class Gemma3Model(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        # 确保 layer_types 配置存在且长度等于层数\n",
        "        assert cfg[\"layer_types\"] is not None and len(cfg[\"layer_types\"]) == cfg[\"n_layers\"]\n",
        "\n",
        "        # 主要模型参数\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"]) # token embedding 层\n",
        "\n",
        "        # Transformer 块列表，根据 layer_types 配置构建不同类型的注意力块\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(cfg, attn_type)for attn_type in cfg[\"layer_types\"]\n",
        "        ])\n",
        "\n",
        "        self.final_norm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6) # 最终 LayerNorm\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False, dtype=cfg[\"dtype\"]) # 输出头 (用于预测下一个 token)\n",
        "        self.cfg = cfg # 保存配置字典\n",
        "\n",
        "        # 可重复使用的工具\n",
        "        # 计算局部 RoPE 参数 (用于滑动窗口注意力)\n",
        "        cos_local, sin_local = compute_rope_params(\n",
        "            head_dim=cfg[\"head_dim\"],\n",
        "            theta_base=cfg[\"rope_local_base\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            dtype=torch.float32,\n",
        "        )\n",
        "        # 计算全局 RoPE 参数 (用于全局注意力)\n",
        "        cos_global, sin_global = compute_rope_params(\n",
        "            head_dim=cfg[\"head_dim\"],\n",
        "            theta_base=cfg[\"rope_base\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            dtype=torch.float32,\n",
        "        )\n",
        "        # 将 RoPE 参数注册为 buffer，它们不是模型参数，但需要保存状态\n",
        "        self.register_buffer(\"cos_local\", cos_local, persistent=False)\n",
        "        self.register_buffer(\"sin_local\", sin_local, persistent=False)\n",
        "        self.register_buffer(\"cos_global\", cos_global, persistent=False)\n",
        "        self.register_buffer(\"sin_global\", sin_global, persistent=False)\n",
        "\n",
        "    # 创建注意力掩码\n",
        "    def _create_masks(self, seq_len, device):\n",
        "        # 创建一个全 1 的布尔张量\n",
        "        ones = torch.ones((seq_len, seq_len), dtype=torch.bool, device=device)\n",
        "\n",
        "        # mask_global (掩盖未来：j > i)\n",
        "        # 使用 triu 创建上三角矩阵，对角线偏移 1\n",
        "        mask_global = torch.triu(ones, diagonal=1)\n",
        "\n",
        "        # far_past (掩盖过远的过去：i - j >= sliding_window)\n",
        "        # 使用 triu 创建上三角矩阵，对角线偏移 sliding_window，然后转置\n",
        "        far_past = torch.triu(ones, diagonal=self.cfg[\"sliding_window\"]).T\n",
        "\n",
        "        # Local (sliding_window) = 未来 OR 过远的过去 (掩码)\n",
        "        # 将 mask_global 和 far_past 进行逻辑或运算\n",
        "        mask_local = mask_global | far_past\n",
        "        return mask_global, mask_local # 返回全局掩码和局部掩码\n",
        "\n",
        "    # 定义前向传播\n",
        "    def forward(self, input_ids):\n",
        "        # 获取批次大小和序列长度\n",
        "        b, seq_len = input_ids.shape\n",
        "        # 应用 token embedding，并进行缩放 (Gemma 使用特殊的缩放因子)\n",
        "        x = self.tok_emb(input_ids) * (self.cfg[\"emb_dim\"] ** 0.5)\n",
        "        # 创建注意力掩码\n",
        "        mask_global, mask_local = self._create_masks(seq_len, x.device)\n",
        "\n",
        "        # 遍历每个 Transformer 块并应用前向传播\n",
        "        for block in self.blocks:\n",
        "            x = block(\n",
        "                x,\n",
        "                mask_global=mask_global,\n",
        "                mask_local=mask_local,\n",
        "                cos_global=self.cos_global,\n",
        "                sin_global=self.sin_global,\n",
        "                cos_local=self.cos_local,\n",
        "                sin_local=self.sin_local,\n",
        "            )\n",
        "\n",
        "        # 应用最终 LayerNorm\n",
        "        x = self.final_norm(x)\n",
        "        # 应用输出头预测 logits，并转换到配置的数据类型\n",
        "        logits = self.out_head(x.to(self.cfg[\"dtype\"]))\n",
        "        return logits # 返回 logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be2d201f-74ad-4d63-ab9c-601b00674a48",
      "metadata": {
        "id": "be2d201f-74ad-4d63-ab9c-601b00674a48"
      },
      "source": [
        "&nbsp;\n",
        "# 2. Initialize model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "caa142fa-b375-4e78-b392-2072ced666f3",
      "metadata": {
        "id": "caa142fa-b375-4e78-b392-2072ced666f3"
      },
      "outputs": [],
      "source": [
        "# Gemma3 270M 模型的配置字典\n",
        "GEMMA3_CONFIG_270M = {\n",
        "    \"vocab_size\": 262_144, # 词汇表大小\n",
        "    \"context_length\": 32_768, # 上下文长度\n",
        "    \"emb_dim\": 640, # 嵌入维度\n",
        "    \"n_heads\": 4, # 注意力头的数量\n",
        "    \"n_layers\": 18, # Transformer 层的数量\n",
        "    \"hidden_dim\": 2048, # 前馈网络的隐藏层维度\n",
        "    \"head_dim\": 256, # 每个注意力头的维度\n",
        "    \"qk_norm\": True, # 是否进行 QK 归一化\n",
        "    \"n_kv_groups\": 1, # KV 组的数量 (1 表示多头注意力 MHA)\n",
        "    \"rope_local_base\": 10_000.0, # 局部 RoPE 的 theta_base\n",
        "    \"rope_base\": 1_000_000.0, # 全局 RoPE 的 theta_base\n",
        "    \"sliding_window\": 512, # 滑动窗口大小\n",
        "      \"layer_types\": [ # 每层的注意力类型\n",
        "        \"sliding_attention\", # 滑动窗口注意力\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"full_attention\", # 全局注意力\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"full_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"full_attention\"\n",
        "    ],\n",
        "    \"dtype\": torch.bfloat16, # 模型使用的数据类型\n",
        "    \"query_pre_attn_scalar\": 256, # 查询在注意力计算前的缩放因子\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "156253fe-aacd-4da2-8f13-705f05c4b11e",
      "metadata": {
        "id": "156253fe-aacd-4da2-8f13-705f05c4b11e"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123) # 设置随机种子以确保可复现性\n",
        "model = Gemma3Model(GEMMA3_CONFIG_270M) # 使用配置初始化 Gemma3 模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "eaf86265-4e9d-4024-9ed0-99076944e304",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaf86265-4e9d-4024-9ed0-99076944e304",
        "outputId": "8fa3fb97-e43a-4bca-e605-83368477968f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Gemma3Model(\n",
              "  (tok_emb): Embedding(262144, 640)\n",
              "  (blocks): ModuleList(\n",
              "    (0-17): 18 x TransformerBlock(\n",
              "      (att): GroupedQueryAttention(\n",
              "        (W_query): Linear(in_features=640, out_features=1024, bias=False)\n",
              "        (W_key): Linear(in_features=640, out_features=256, bias=False)\n",
              "        (W_value): Linear(in_features=640, out_features=256, bias=False)\n",
              "        (out_proj): Linear(in_features=1024, out_features=640, bias=False)\n",
              "        (q_norm): RMSNorm()\n",
              "        (k_norm): RMSNorm()\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (fc1): Linear(in_features=640, out_features=2048, bias=False)\n",
              "        (fc2): Linear(in_features=640, out_features=2048, bias=False)\n",
              "        (fc3): Linear(in_features=2048, out_features=640, bias=False)\n",
              "      )\n",
              "      (input_layernorm): RMSNorm()\n",
              "      (post_attention_layernorm): RMSNorm()\n",
              "      (pre_feedforward_layernorm): RMSNorm()\n",
              "      (post_feedforward_layernorm): RMSNorm()\n",
              "    )\n",
              "  )\n",
              "  (final_norm): RMSNorm()\n",
              "  (out_head): Linear(in_features=640, out_features=262144, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model # 打印模型结构"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90aca91d-4bee-45ce-993a-4ec5393abe2b",
      "metadata": {
        "id": "90aca91d-4bee-45ce-993a-4ec5393abe2b"
      },
      "source": [
        "- A quick check that the forward pass works before continuing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "adf0a6b7-b688-42c9-966e-c223d34db99f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adf0a6b7-b688-42c9-966e-c223d34db99f",
        "outputId": "6da093fd-fda0-46b2-d942-47b93c6d02dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7500,  0.1055,  0.4844,  ...,  0.9414,  0.3984, -0.2354],\n",
              "         [-0.3418, -0.0542,  0.8945,  ..., -0.2383,  0.4590,  0.8242],\n",
              "         [-0.2676, -0.3301,  0.4141,  ...,  0.8672, -0.9688,  0.9844]]],\n",
              "       dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# 对输入张量进行一次前向传播，检查模型是否正常工作\n",
        "# torch.tensor([1, 2, 3]) 创建一个张量\n",
        "# .unsqueeze(0) 在第 0 维增加一个批次维度\n",
        "model(torch.tensor([1, 2, 3]).unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "364e76ca-52f8-4fa5-af37-c4069f9694bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "364e76ca-52f8-4fa5-af37-c4069f9694bc",
        "outputId": "7c7744ce-414a-4723-976e-892b27d5f917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 435,870,336\n",
            "\n",
            "Total number of unique parameters: 268,098,176\n"
          ]
        }
      ],
      "source": [
        "# 计算模型参数总数\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\") # 打印参数总数\n",
        "\n",
        "# 考虑权重共享，计算唯一的参数总数\n",
        "# 总参数减去 token embedding 层的参数数量（因为输出头与 token embedding 共享权重）\n",
        "total_params_normalized = total_params - model.tok_emb.weight.numel()\n",
        "print(f\"\\nTotal number of unique parameters: {total_params_normalized:,}\") # 打印唯一的参数总数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fd5efb03-5a07-46e8-8607-93ed47549d2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd5efb03-5a07-46e8-8607-93ed47549d2b",
        "outputId": "7d13d770-91a5-4b11-bf22-2ef3af5bd65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float32 (PyTorch default): 3.37 GB\n",
            "bfloat16: 1.69 GB\n"
          ]
        }
      ],
      "source": [
        "# 计算模型内存大小\n",
        "def model_memory_size(model, input_dtype=torch.float32):\n",
        "    total_params = 0 # 参数总数\n",
        "    total_grads = 0 # 梯度总数\n",
        "    # 遍历模型参数\n",
        "    for param in model.parameters():\n",
        "        # 计算每个参数的元素总数\n",
        "        param_size = param.numel()\n",
        "        total_params += param_size\n",
        "        # 检查参数是否需要计算梯度\n",
        "        if param.requires_grad:\n",
        "            total_grads += param_size\n",
        "\n",
        "    # 计算 buffer 的大小 (非参数但需要内存)\n",
        "    total_buffers = sum(buf.numel() for buf in model.buffers())\n",
        "\n",
        "    # 计算总内存大小 (字节) = (参数数量 + 梯度数量 + buffer 数量) * 元素大小\n",
        "    # 假设参数和梯度使用与输入 dtype 相同的数据类型存储\n",
        "    element_size = torch.tensor(0, dtype=input_dtype).element_size()\n",
        "    total_memory_bytes = (total_params + total_grads + total_buffers) * element_size\n",
        "\n",
        "    # 将字节转换为千兆字节 (GB)\n",
        "    total_memory_gb = total_memory_bytes / (1024**3)\n",
        "\n",
        "    return total_memory_gb # 返回内存大小 (GB)\n",
        "\n",
        "# 打印不同数据类型下的模型内存大小\n",
        "print(f\"float32 (PyTorch default): {model_memory_size(model, input_dtype=torch.float32):.2f} GB\")\n",
        "print(f\"bfloat16: {model_memory_size(model, input_dtype=torch.bfloat16):.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "31f12baf-f79b-499f-85c0-51328a6a20f5",
      "metadata": {
        "id": "31f12baf-f79b-499f-85c0-51328a6a20f5"
      },
      "outputs": [],
      "source": [
        "# 检查是否有可用的 CUDA 设备，否则检查 MPS 设备，最后使用 CPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\") # 使用 CUDA\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\") # 使用 MPS (Mac)\n",
        "else:\n",
        "    device = torch.device(\"cpu\") # 使用 CPU\n",
        "\n",
        "model.to(device); # 将模型移动到选定的设备上"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c172f89f-d301-439f-b809-46169e5f5945",
      "metadata": {
        "id": "c172f89f-d301-439f-b809-46169e5f5945"
      },
      "source": [
        "&nbsp;\n",
        "# 4. Load pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "75166128-5899-4995-9b88-9672e135650e",
      "metadata": {
        "id": "75166128-5899-4995-9b88-9672e135650e"
      },
      "outputs": [],
      "source": [
        "# 将预训练权重加载到 Gemma 模型中\n",
        "def load_weights_into_gemma(Gemma3Model, param_config, params):\n",
        "\n",
        "    # 辅助函数：将源张量赋值给目标张量，并进行形状检查\n",
        "    def assign(left, right, tensor_name=\"unknown\"):\n",
        "        if left.shape != right.shape:\n",
        "            raise ValueError(\n",
        "                f\"Shape mismatch in tensor '{tensor_name}'. Left: {left.shape}, Right: {right.shape}\"\n",
        "            )\n",
        "        # 克隆并分离张量，然后转换为 nn.Parameter\n",
        "        return torch.nn.Parameter(right.clone().detach() if isinstance(right, torch.Tensor) else torch.tensor(right))\n",
        "\n",
        "    # 加载 Embedding 权重\n",
        "    if \"model.embed_tokens.weight\" in params:\n",
        "        model.tok_emb.weight = assign(\n",
        "            model.tok_emb.weight,\n",
        "            params[\"model.embed_tokens.weight\"],\n",
        "            \"model.embed_tokens.weight\",\n",
        "        )\n",
        "\n",
        "    # 遍历 Transformer 层并加载权重\n",
        "    for l in range(param_config[\"n_layers\"]):\n",
        "        block = model.blocks[l] # 获取当前 Transformer 块\n",
        "        att = block.att # 获取当前注意力层\n",
        "        # 注意力投影权重\n",
        "        att.W_query.weight = assign(\n",
        "            att.W_query.weight,\n",
        "            params[f\"model.layers.{l}.self_attn.q_proj.weight\"],\n",
        "            f\"model.layers.{l}.self_attn.q_proj.weight\",\n",
        "        )\n",
        "        att.W_key.weight = assign(\n",
        "            att.W_key.weight,\n",
        "            params[f\"model.layers.{l}.self_attn.k_proj.weight\"],\n",
        "            f\"model.layers.{l}.self_attn.k_proj.weight\",\n",
        "        )\n",
        "        att.W_value.weight = assign(\n",
        "            att.W_value.weight,\n",
        "            params[f\"model.layers.{l}.self_attn.v_proj.weight\"],\n",
        "            f\"model.layers.{l}.self_attn.v_proj.weight\",\n",
        "        )\n",
        "        att.out_proj.weight = assign(\n",
        "            att.out_proj.weight,\n",
        "            params[f\"model.layers.{l}.self_attn.o_proj.weight\"],\n",
        "            f\"model.layers.{l}.self_attn.o_proj.weight\",\n",
        "        )\n",
        "        # QK 归一化权重\n",
        "        att.q_norm.scale = assign(\n",
        "            att.q_norm.scale,\n",
        "            params[f\"model.layers.{l}.self_attn.q_norm.weight\"],\n",
        "            f\"model.layers.{l}.self_attn.q_norm.weight\",\n",
        "        )\n",
        "        att.k_norm.scale = assign(\n",
        "            att.k_norm.scale,\n",
        "            params[f\"model.layers.{l}.self_attn.k_norm.weight\"],\n",
        "            f\"model.layers.{l}.self_attn.k_norm.weight\",\n",
        "        )\n",
        "        # 前馈网络权重\n",
        "        block.ff.fc1.weight = assign(\n",
        "            block.ff.fc1.weight,\n",
        "            params[f\"model.layers.{l}.mlp.gate_proj.weight\"],\n",
        "            f\"model.layers.{l}.mlp.gate_proj.weight\",\n",
        "        )\n",
        "        block.ff.fc2.weight = assign(\n",
        "            block.ff.fc2.weight,\n",
        "            params[f\"model.layers.{l}.mlp.up_proj.weight\"],\n",
        "            f\"model.layers.{l}.mlp.up_proj.weight\",\n",
        "        )\n",
        "        block.ff.fc3.weight = assign(\n",
        "            block.ff.fc3.weight,\n",
        "            params[f\"model.layers.{l}.mlp.down_proj.weight\"],\n",
        "            f\"model.layers.{l}.mlp.down_proj.weight\",\n",
        "        )\n",
        "        # LayerNorm 权重\n",
        "        block.input_layernorm.scale = assign(\n",
        "            block.input_layernorm.scale,\n",
        "            params[f\"model.layers.{l}.input_layernorm.weight\"],\n",
        "            f\"model.layers.{l}.input_layernorm.weight\",\n",
        "        )\n",
        "        block.post_attention_layernorm.scale = assign(\n",
        "            block.post_attention_layernorm.scale,\n",
        "            params[f\"model.layers.{l}.post_attention_layernorm.weight\"],\n",
        "            f\"model.layers.{l}.post_attention_layernorm.weight\",\n",
        "        )\n",
        "        # 前馈网络前和后 LayerNorm 权重\n",
        "        pre_key = f\"model.layers.{l}.pre_feedforward_layernorm.weight\"\n",
        "        post_key = f\"model.layers.{l}.post_feedforward_layernorm.weight\"\n",
        "        if pre_key in params:\n",
        "            block.pre_feedforward_layernorm.scale = assign(\n",
        "                block.pre_feedforward_layernorm.scale,\n",
        "                params[pre_key],\n",
        "                pre_key,\n",
        "            )\n",
        "        if post_key in params:\n",
        "            block.post_feedforward_layernorm.scale = assign(\n",
        "                block.post_feedforward_layernorm.scale,\n",
        "                params[post_key],\n",
        "                post_key,\n",
        "            )\n",
        "\n",
        "    # 加载最终 LayerNorm 权重\n",
        "    if \"model.norm.weight\" in params:\n",
        "        model.final_norm.scale = assign(\n",
        "            model.final_norm.scale,\n",
        "            params[\"model.norm.weight\"],\n",
        "            \"model.norm.weight\",\n",
        "        )\n",
        "    # 加载输出头权重\n",
        "    if \"lm_head.weight\" in params:\n",
        "        model.out_head.weight = assign(\n",
        "            model.out_head.weight,\n",
        "            params[\"lm_head.weight\"],\n",
        "            \"lm_head.weight\",\n",
        "        )\n",
        "    elif \"model.embed_tokens.weight\" in params:\n",
        "        # 权重共享：重用 embedding 权重作为输出头权重\n",
        "        model.out_head.weight = assign(\n",
        "            model.out_head.weight,\n",
        "            params[\"model.embed_tokens.weight\"],\n",
        "            \"model.embed_tokens.weight\",\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "430340f2-78b9-4983-b74e-8395bbd7e574",
      "metadata": {
        "id": "430340f2-78b9-4983-b74e-8395bbd7e574"
      },
      "source": [
        "- Please note that Google requires that you accept the Gemma 3 licensing terms before you can download the files; to do this, you have to create a Hugging Face Hub account and visit the [google/gemma-3-270m]https://huggingface.co/google/gemma-3-270m) repository to accept the terms\n",
        "- Next, you will need to create an access token; to generate an access token with READ permissions, click on the profile picture in the upper right and click on \"Settings\"\n",
        "\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/gpt-to-llama/settings.webp?1\" width=\"300px\">\n",
        "\n",
        "- Then, create and copy the access token so you can copy & paste it into the next code cell\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/gpt-to-llama/access-token.webp?1\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7cee5292-f756-41dd-9b8d-c9b5c25d23f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "e324d315bdf7410d94b7716ce75ef37e",
            "7bd5c7d3fe624665a7280f7fbdebe78d",
            "dd137564e6074bfdaa34322dfc2141a8",
            "dd5e571a662647eab327681f77a9ef5f",
            "bb7b28e1461e4a2bba36b53975258844",
            "33170e2b21024fb3ae9c55790c66360a",
            "3d300c424a524e56a4a8df09c3ace7af",
            "35aa590d00ef493fafe7d1f74e695edf",
            "6a1204de7a1a479b87516da3b4e6a776",
            "31b64b4a69374e0081819a4c33b80590",
            "2d0aecd32f48463caa6095a81a5d870d",
            "181a3a41ac494f7ea362442fa2c7a64c",
            "6612b8449ff94d7ba854d8927aa0ddf8",
            "b422b814990c449fa1614492d48913c3",
            "98bc0b2bf8084b94bbe2ab3f9415b0af",
            "34c02f3f46774003a3faedda6abdb58e",
            "0b9bccadf4684a0aa1a71f6ddd4b27c7"
          ]
        },
        "id": "7cee5292-f756-41dd-9b8d-c9b5c25d23f8",
        "outputId": "b9d82dd0-8d39-4f6e-eac8-f46ed7bf1e06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e324d315bdf7410d94b7716ce75ef37e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 如果是第一次运行 notebook，取消注释并运行以下代码进行 huggingface_hub 登录\n",
        "\n",
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "WW2pZk6GK3ZY"
      },
      "id": "WW2pZk6GK3ZY",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "8DjyRz2FK3ZZ"
      },
      "id": "8DjyRz2FK3ZZ"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "w9gbO2RUK3ZZ"
      },
      "id": "w9gbO2RUK3ZZ",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "699cb1b8-a67d-49fb-80a6-0dad9d81f392",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35,
          "referenced_widgets": [
            "d6b7e3b8b79d4da28f61d56bc8c28a1e",
            "3b2e7e85bbd344abab635412ce8aef12",
            "dbcb0f80d3f34a2db9fff43ee5ea1558",
            "6833ce8092834174b320832ee8f3d627",
            "881f8f05008a48f2a2bc8ade6a1805ce",
            "f28ff13974524ec6be10afc935e26488",
            "3af73e3b29924c6cb15ae0bcc7a52171",
            "969e9d3a8f7e4952931d508f75064253",
            "3306999b69cc4900bdab5550f7f53ec9",
            "16d3f1947be74481aefe5d7c00f77975",
            "112486cbe759462d8b9a082f4ed5b35c"
          ]
        },
        "id": "699cb1b8-a67d-49fb-80a6-0dad9d81f392",
        "outputId": "d2d83deb-7156-438d-ca54-2f298aa3f782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully logged in to Hugging Face Hub.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/536M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6b7e3b8b79d4da28f61d56bc8c28a1e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from safetensors.torch import load_file # 从 safetensors 文件加载权重\n",
        "from huggingface_hub import hf_hub_download, snapshot_download # 从 Hugging Face Hub 下载文件\n",
        "from google.colab import userdata # 导入用于访问 Colab Secrets 的模块\n",
        "from huggingface_hub import login # 导入 login 函数\n",
        "\n",
        "# 从 Colab Secrets 获取 Hugging Face 令牌并登录\n",
        "try:\n",
        "    hf_token = userdata.get('HF_TOKEN')\n",
        "    if hf_token:\n",
        "        login(token=hf_token)\n",
        "        print(\"Successfully logged in to Hugging Face Hub.\")\n",
        "    else:\n",
        "        print(\"Hugging Face token not found in Colab Secrets. Please add it.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during Hugging Face login: {e}\")\n",
        "\n",
        "\n",
        "CHOOSE_MODEL = \"270m\" # 选择模型大小\n",
        "\n",
        "# 根据 USE_INSTRUCT_MODEL 标志确定 Hugging Face Hub 仓库 ID\n",
        "if USE_INSTRUCT_MODEL:\n",
        "    repo_id = f\"google/gemma-3-{CHOOSE_MODEL}-it\" # 指令模型仓库 ID\n",
        "else:\n",
        "    repo_id = f\"google/gemma-3-{CHOOSE_MODEL}\" # 基础模型仓库 ID\n",
        "\n",
        "\n",
        "local_dir = Path(repo_id).parts[-1] # 定义本地存储目录\n",
        "\n",
        "# 根据模型大小选择下载方式\n",
        "if CHOOSE_MODEL == \"270m\":\n",
        "    # 对于 270M 模型，直接下载 model.safetensors 文件\n",
        "    weights_file = hf_hub_download(\n",
        "        repo_id=repo_id, # 仓库 ID\n",
        "        filename=\"model.safetensors\", # 文件名\n",
        "        local_dir=local_dir, # 本地存储目录\n",
        "    )\n",
        "    weights_dict = load_file(weights_file) # 从 safetensors 文件加载权重到字典\n",
        "else:\n",
        "    # 对于其他模型大小 (如果存在分片)，下载整个仓库快照\n",
        "    repo_dir = snapshot_download(repo_id=repo_id, local_dir=local_dir)\n",
        "    index_path = os.path.join(repo_dir, \"model.safetensors.index.json\") # 权重索引文件路径\n",
        "    with open(index_path, \"r\") as f:\n",
        "        index = json.load(f) # 加载权重索引\n",
        "\n",
        "    weights_dict = {} # 初始化权重字典\n",
        "    # 遍历索引中的文件名并加载权重\n",
        "    for filename in set(index[\"weight_map\"].values()):\n",
        "        shard_path = os.path.join(repo_dir, filename) # 分片文件路径\n",
        "        shard = load_file(shard_path) # 加载分片权重\n",
        "        weights_dict.update(shard) # 更新权重字典\n",
        "\n",
        "# 将加载的权重加载到模型中\n",
        "load_weights_into_gemma(model, GEMMA3_CONFIG_270M, weights_dict)\n",
        "model.to(device) # 将模型移动到设备\n",
        "del weights_dict # 删除权重字典以释放内存"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b345491-3510-4397-92d3-cd0a3fa3deee",
      "metadata": {
        "id": "6b345491-3510-4397-92d3-cd0a3fa3deee"
      },
      "source": [
        "&nbsp;\n",
        "# 4. Load tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b68ab489-48e5-471e-a814-56cda2d60f81",
      "metadata": {
        "id": "b68ab489-48e5-471e-a814-56cda2d60f81"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer # 导入 Tokenizer 类\n",
        "\n",
        "# 定义 Gemma 分词器类\n",
        "class GemmaTokenizer:\n",
        "    def __init__(self, tokenizer_file_path: str):\n",
        "        tok_file = Path(tokenizer_file_path) # 创建 Path 对象\n",
        "        self._tok = Tokenizer.from_file(str(tok_file)) # 从文件加载分词器\n",
        "        # 尝试识别 EOS 和 padding token\n",
        "        eos_token = \"<end_of_turn>\" # 定义 EOS token 字符串\n",
        "        self.pad_token_id = eos_token # 设置 padding token ID\n",
        "        self.eos_token_id = eos_token # 设置 EOS token ID\n",
        "\n",
        "    # 将文本编码为 token ID 列表\n",
        "    def encode(self, text: str) -> list[int]:\n",
        "        return self._tok.encode(text).ids\n",
        "\n",
        "    # 将 token ID 列表解码为文本\n",
        "    def decode(self, ids: list[int]) -> str:\n",
        "        return self._tok.decode(ids, skip_special_tokens=False) # 不跳过特殊 token\n",
        "\n",
        "# 应用聊天模板，格式化用户输入\n",
        "def apply_chat_template(user_text):\n",
        "    return f\"<start_of_turn>user\\n{user_text}<end_of_turn>\\n<start_of_turn>model\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7b6df8bc-7308-468e-93ce-2d5529ea7866",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "bb557cb67b3b4e9ba4907ccd05941138",
            "abbcb6dfd94b479fb495f40306a6fb7d",
            "04994e115a6e486e8cbb74e9409df7ab",
            "cbf4b3b00a4247958c1be2745209555a",
            "2c9bf6c706084216ae8b4e39c50cbd7d",
            "75f58eda52894911bed3d68fc3058191",
            "f64addaca06748778074e9f8435c7ebf",
            "a8f335bccc744fe09c6cb41a7ea692db",
            "45d83aee794b4af38d72d4d47f1e2f20",
            "fae0ad11815743afbfa71e50cc779260",
            "6f85c07fa86e46368c4137c205291300"
          ]
        },
        "id": "7b6df8bc-7308-468e-93ce-2d5529ea7866",
        "outputId": "16b8b30c-c971-45c4-c2a3-95ee27b5db4d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb557cb67b3b4e9ba4907ccd05941138"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer_file_path = os.path.join(local_dir, \"tokenizer.json\") # 构建 tokenizer 文件路径\n",
        "# 如果文件不存在，则尝试从 Hugging Face Hub 下载\n",
        "if not os.path.exists(tokenizer_file_path):\n",
        "    try:\n",
        "        tokenizer_file_path = hf_hub_download(repo_id=repo_id, filename=\"tokenizer.json\", local_dir=local_dir)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: failed to download tokenizer.json: {e}\")\n",
        "        tokenizer_file_path = \"tokenizer.json\" # 如果下载失败，使用默认文件名\n",
        "\n",
        "tokenizer = GemmaTokenizer(tokenizer_file_path=tokenizer_file_path) # 初始化 Gemma 分词器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "1946b534-e3af-431a-a222-391a60bfa892",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1946b534-e3af-431a-a222-391a60bfa892",
        "outputId": "ce3845de-dd5a-4fee-dfca-757d9a084ccb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<bos><start_of_turn>user\\n深入浅出地用简体中文解释一下统计学中的三门问题<end_of_turn>\\n<start_of_turn>model\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "prompt = \"深入浅出地用简体中文解释一下统计学中的三门问题\" # 定义原始 prompt\n",
        "# 应用聊天模板格式化 prompt\n",
        "prompt = apply_chat_template(\"深入浅出地用简体中文解释一下统计学中的三门问题\")\n",
        "\n",
        "\n",
        "input_token_ids = tokenizer.encode(prompt) # 将 prompt 编码为 token ID 列表\n",
        "text = tokenizer.decode(input_token_ids) # 将 token ID 列表解码回文本\n",
        "text # 打印解码后的文本 (包含特殊 token)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d07df1-4401-4792-b549-7c4cc5632323",
      "metadata": {
        "id": "57d07df1-4401-4792-b549-7c4cc5632323"
      },
      "source": [
        "&nbsp;\n",
        "# 5. Generate text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "7b8401c6-e244-4cb7-9849-2ba71ce758d5",
      "metadata": {
        "id": "7b8401c6-e244-4cb7-9849-2ba71ce758d5"
      },
      "outputs": [],
      "source": [
        "# 定义基本的文本生成器 (流式输出)\n",
        "def generate_text_basic_stream(model, token_ids, max_new_tokens, eos_token_id=None):\n",
        "\n",
        "    model.eval() # 将模型设置为评估模式\n",
        "    with torch.no_grad(): # 禁用梯度计算\n",
        "        # 循环生成 max_new_tokens 个 token\n",
        "        for _ in range(max_new_tokens):\n",
        "            # 前向传播，获取最后一个 token 位置的 logits\n",
        "            out = model(token_ids)[:, -1]\n",
        "            # 找到 logits 中概率最大的 token 作为下一个 token\n",
        "            next_token = torch.argmax(out, dim=-1, keepdim=True)\n",
        "\n",
        "            # 如果生成了 EOS token，则停止生成\n",
        "            if (eos_token_id is not None\n",
        "                   and torch.all(next_token == eos_token_id)):\n",
        "               break\n",
        "\n",
        "            yield next_token # 生成下一个 token\n",
        "\n",
        "            # 将新生成的 token 添加到 token_ids 中\n",
        "            token_ids = torch.cat([token_ids, next_token], dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "1c7a04fa-6aac-416b-8f63-f1e19227633d",
      "metadata": {
        "id": "1c7a04fa-6aac-416b-8f63-f1e19227633d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa31d87-6015-4804-d18b-8ac991dca46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "好的，下面是深入浅出地用简体中文解释一下统计学中的三门问题：\n",
            "\n",
            "**1. 检验假设 (Hypothesis Testing)**\n",
            "\n",
            "*   **定义:** 检验一个假设是否成立，即一个假设的概率大于或等于另一个假设的概率。\n",
            "*   **原理:** 统计学中，假设检验的核心是检验一个假设的**概率**。 假设检验的目的是确定一个假设的**概率**，即它是否真的存在。\n",
            "*   **步骤:**\n",
            "    1.  **确定假设:** 确定一个假设的概率。\n",
            "    2.  **确定假设的概率:** 确定假设的概率。\n",
            "    3.  **计算假设的概率:** 计算假设的概率。\n",
            "    4.  **检验假设:** 检查假设的概率是否大于或等于另一个假设的概率。\n",
            "*   **例子:**\n",
            "    *   假设： 假设一个新车价格是 1000 元。\n",
            "    *   假设的概率： 1/1000\n",
            "    *   假设的概率： 100%\n",
            "    *   检验假设： 100% > 1/1000\n",
            "    *   结果： 假设的概率大于另一个假设的概率。\n",
            "\n",
            "**2. 统计量 (Statistical Tests)**\n",
            "\n",
            "*   **定义:** 统计量是统计学中用来检验一个假设的**统计量**。 统计量是衡量一个假设的**统计特征**的指标。\n",
            "*   **原理:** 统计量是统计学中用来检验一个假设的**统计量**。 统计量是衡量一个假设的**统计量**。\n",
            "*   **步骤:**\n",
            "    1.  **确定统计量:** 确定一个统计量。\n",
            "    2.  **计算统计量:** 计算一个统计量。\n",
            "    3.  **检验统计量:** 检查统计量是否满足一个**假设**。\n",
            "*   **例子:**\n",
            "    *   假设： 假设一个新公司的员工工资是 500 元。\n",
            "    *   假设的统计量： 500\n",
            "    *   假设的概率： 50%\n",
            "    *   假设的概率： 50%\n",
            "    *   检验统计量： 50% > 50%\n",
            "    *   结果： 假设的"
          ]
        }
      ],
      "source": [
        "# 将输入 token ID 列表转换为张量，并增加批次维度，移动到设备上\n",
        "input_token_ids_tensor = torch.tensor(input_token_ids, device=device).unsqueeze(0)\n",
        "\n",
        "# 使用流式生成器生成文本并打印\n",
        "for token in generate_text_basic_stream(\n",
        "    model=model, # 模型\n",
        "    token_ids=input_token_ids_tensor, # 输入 token ID 张量\n",
        "    max_new_tokens=500, # 最大生成 token 数量\n",
        "    eos_token_id=tokenizer.encode(\"<end_of_turn>\")[-1] # EOS token ID\n",
        "):\n",
        "    token_id = token.squeeze(0).tolist() # 从张量中提取 token ID 并转换为列表\n",
        "    # 解码 token ID 并打印，不换行，并刷新输出缓冲区\n",
        "    print(\n",
        "        tokenizer.decode(token_id),\n",
        "        end=\"\",\n",
        "        flush=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "549324d6-5c71-4147-ae21-2e67675faa3d",
      "metadata": {
        "id": "549324d6-5c71-4147-ae21-2e67675faa3d"
      },
      "source": [
        "&nbsp;\n",
        "# What's next?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6edaaae-2de1-406c-8ffa-897cdfa3808c",
      "metadata": {
        "id": "e6edaaae-2de1-406c-8ffa-897cdfa3808c"
      },
      "source": [
        "- Check out the [README.md](./README.md), to use this model via the `llms_from_scratch` package\n",
        "- For those interested in a comprehensive guide on building a large language model from scratch and gaining a deeper understanding of its mechanics, you might like my [Build a Large Language Model (From Scratch)](http://mng.bz/orYv)\n",
        "\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e324d315bdf7410d94b7716ce75ef37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bd5c7d3fe624665a7280f7fbdebe78d",
              "IPY_MODEL_dd137564e6074bfdaa34322dfc2141a8",
              "IPY_MODEL_dd5e571a662647eab327681f77a9ef5f",
              "IPY_MODEL_bb7b28e1461e4a2bba36b53975258844",
              "IPY_MODEL_33170e2b21024fb3ae9c55790c66360a"
            ],
            "layout": "IPY_MODEL_3d300c424a524e56a4a8df09c3ace7af",
            "tabbable": null,
            "tooltip": null
          }
        },
        "7bd5c7d3fe624665a7280f7fbdebe78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_35aa590d00ef493fafe7d1f74e695edf",
            "placeholder": "​",
            "style": "IPY_MODEL_6a1204de7a1a479b87516da3b4e6a776",
            "tabbable": null,
            "tooltip": null,
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "dd137564e6074bfdaa34322dfc2141a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_allow_html": false,
            "disabled": false,
            "layout": "IPY_MODEL_31b64b4a69374e0081819a4c33b80590",
            "placeholder": "​",
            "style": "IPY_MODEL_2d0aecd32f48463caa6095a81a5d870d",
            "tabbable": null,
            "tooltip": null,
            "value": ""
          }
        },
        "dd5e571a662647eab327681f77a9ef5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_allow_html": false,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_181a3a41ac494f7ea362442fa2c7a64c",
            "style": "IPY_MODEL_6612b8449ff94d7ba854d8927aa0ddf8",
            "tabbable": null,
            "tooltip": null,
            "value": true
          }
        },
        "bb7b28e1461e4a2bba36b53975258844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b422b814990c449fa1614492d48913c3",
            "style": "IPY_MODEL_98bc0b2bf8084b94bbe2ab3f9415b0af",
            "tabbable": null,
            "tooltip": null
          }
        },
        "33170e2b21024fb3ae9c55790c66360a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_34c02f3f46774003a3faedda6abdb58e",
            "placeholder": "​",
            "style": "IPY_MODEL_0b9bccadf4684a0aa1a71f6ddd4b27c7",
            "tabbable": null,
            "tooltip": null,
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "3d300c424a524e56a4a8df09c3ace7af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "35aa590d00ef493fafe7d1f74e695edf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a1204de7a1a479b87516da3b4e6a776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "31b64b4a69374e0081819a4c33b80590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d0aecd32f48463caa6095a81a5d870d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "TextStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "181a3a41ac494f7ea362442fa2c7a64c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6612b8449ff94d7ba854d8927aa0ddf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "CheckboxStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": ""
          }
        },
        "b422b814990c449fa1614492d48913c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98bc0b2bf8084b94bbe2ab3f9415b0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "34c02f3f46774003a3faedda6abdb58e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9bccadf4684a0aa1a71f6ddd4b27c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "d6b7e3b8b79d4da28f61d56bc8c28a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b2e7e85bbd344abab635412ce8aef12",
              "IPY_MODEL_dbcb0f80d3f34a2db9fff43ee5ea1558",
              "IPY_MODEL_6833ce8092834174b320832ee8f3d627"
            ],
            "layout": "IPY_MODEL_881f8f05008a48f2a2bc8ade6a1805ce",
            "tabbable": null,
            "tooltip": null
          }
        },
        "3b2e7e85bbd344abab635412ce8aef12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f28ff13974524ec6be10afc935e26488",
            "placeholder": "​",
            "style": "IPY_MODEL_3af73e3b29924c6cb15ae0bcc7a52171",
            "tabbable": null,
            "tooltip": null,
            "value": "model.safetensors: 100%"
          }
        },
        "dbcb0f80d3f34a2db9fff43ee5ea1558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_969e9d3a8f7e4952931d508f75064253",
            "max": 536223056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3306999b69cc4900bdab5550f7f53ec9",
            "tabbable": null,
            "tooltip": null,
            "value": 536223056
          }
        },
        "6833ce8092834174b320832ee8f3d627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_16d3f1947be74481aefe5d7c00f77975",
            "placeholder": "​",
            "style": "IPY_MODEL_112486cbe759462d8b9a082f4ed5b35c",
            "tabbable": null,
            "tooltip": null,
            "value": " 536M/536M [00:06&lt;00:00, 154MB/s]"
          }
        },
        "881f8f05008a48f2a2bc8ade6a1805ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28ff13974524ec6be10afc935e26488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af73e3b29924c6cb15ae0bcc7a52171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "969e9d3a8f7e4952931d508f75064253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3306999b69cc4900bdab5550f7f53ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16d3f1947be74481aefe5d7c00f77975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "112486cbe759462d8b9a082f4ed5b35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "bb557cb67b3b4e9ba4907ccd05941138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abbcb6dfd94b479fb495f40306a6fb7d",
              "IPY_MODEL_04994e115a6e486e8cbb74e9409df7ab",
              "IPY_MODEL_cbf4b3b00a4247958c1be2745209555a"
            ],
            "layout": "IPY_MODEL_2c9bf6c706084216ae8b4e39c50cbd7d",
            "tabbable": null,
            "tooltip": null
          }
        },
        "abbcb6dfd94b479fb495f40306a6fb7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_75f58eda52894911bed3d68fc3058191",
            "placeholder": "​",
            "style": "IPY_MODEL_f64addaca06748778074e9f8435c7ebf",
            "tabbable": null,
            "tooltip": null,
            "value": "tokenizer.json: 100%"
          }
        },
        "04994e115a6e486e8cbb74e9409df7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a8f335bccc744fe09c6cb41a7ea692db",
            "max": 33384570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45d83aee794b4af38d72d4d47f1e2f20",
            "tabbable": null,
            "tooltip": null,
            "value": 33384570
          }
        },
        "cbf4b3b00a4247958c1be2745209555a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_fae0ad11815743afbfa71e50cc779260",
            "placeholder": "​",
            "style": "IPY_MODEL_6f85c07fa86e46368c4137c205291300",
            "tabbable": null,
            "tooltip": null,
            "value": " 33.4M/33.4M [00:00&lt;00:00, 40.6MB/s]"
          }
        },
        "2c9bf6c706084216ae8b4e39c50cbd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f58eda52894911bed3d68fc3058191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64addaca06748778074e9f8435c7ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a8f335bccc744fe09c6cb41a7ea692db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d83aee794b4af38d72d4d47f1e2f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fae0ad11815743afbfa71e50cc779260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f85c07fa86e46368c4137c205291300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}